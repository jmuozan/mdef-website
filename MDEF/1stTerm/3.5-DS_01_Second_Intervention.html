<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Second Intervention</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Overpass+Mono:wght@500&family=Sora:wght@300;400;500&display=swap" rel="stylesheet">
    <script src="https://kit.fontawesome.com/1ea8c7c824.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="../../css/MDEF_css/1st_Term_css/3.5-DS_01_Second_Intervention.css">
</head>
<body>
    <a href="../../index.html"><p class="boton">Go Back Home ðŸ‘ˆ</p></a>
    <div class="contenedor">
            <div class="textoprincipal">
                <h1 id="titulo">Second Intervention ðŸª´</h1>
                <h2 class="fechas">20/11/2023 - 03/12/2023</h2>
            </div>
        <div class="texto1">
            <p class="texto">Based on our conclusions from the first intervention and the evolution of our design spaces, we were asked to do a second intervention, leading to the design dialogues.Â </p>
        </div>
        <div class="texto2">
            <h2 class="subtitulo">New interests, new group</h2>
            <p class="texto">As I previously mentioned in the first intervention reflections, I wasnâ€™t too motivated by the project because it changed completely from my interests back then. For that reason, based on my newly discovered interests in interspecies collaborations and bio-materials, I decided to look for a new group with similar interests to mine. That way, I joined NicolÃ², Marius, Ever, Albert and Oliver.Â </p>
        </div>
        <div class="img1">
            <img src="../../IMGS/MDEF/Design_Studio/Second_Intervention/Plant-laptop.png" height="350px">
        </div>
        <div class="texto3">
            <h2 class="subtitulo">The project</h2>
            <p class="texto">As I mentioned before, our interests were mostly about interspecies collaboration, especially around sensoring. For this reason we asked ourselves the following: What happens when you connect a plant to your computer? Out of this question, a lot of subquestions came. What kind of signal do we get? Do we actually get signals? What can we measure with that data?â€¦ I really enjoyed this questioning phase because we really thought about future possibilities and we werenâ€™t limited by what has been done until now. Out of this questioning, thereâ€™s a question that I find super interesting and motivated me to get fully involved in the process: Could we do a smart citizen kit were all the sensors are substituted by living organisms? This idea to this day runs around my head, if thatâ€™s possible, would that make the smart citizen kit fully open source, because right now itâ€™s dependent on different sensor produced by different companies were you donâ€™t really now how it has been programmed or assembled on an easy way. </p>
        </div>
        <div class="img2">
            <img src="../../IMGS/MDEF/Design_Studio/Second_Intervention/Cactus.gif" height="380px">
        </div>
        <div class="texto4">
            <h2 class="subtitulo">Experimentation</h2>
            <p class="texto">To approach this intervention, we decided to start by experimenting with the questions we had previously asked ourselves. Instead of starting an extended research project on plants and electronics, we decided to do a little research and, with our actual knowledge, start trying our idea of connecting a plant to our computer. I think this approach was super beneficial because it helped us understand how the electronics and plants work by failing to connect them. After a little previous research, we decided to try to connect a plant via an ECG sensor, like the ones used in humans, but we didnâ€™t succeed in seeing a signal usable. There was a lot of noise, and the reaction when we touched the connected plant was not what we expected. We tried different plants, expecting different reactions, and tried different ways to interact with them once they were connected. By doing this, we knew we were onto something, but the result was not satisfactory. Finally, we found other open source projects of people who had the same questions as us and also tried to answer them. By understanding their electronic set-up and their code and applying it to what we had, we finally got a less noisy signal that we could use with different outputs. For the output, we opted for a visual one. By using Touch Designer, we managed to connect the Arduino data with the screen and create some visuals to show the signals in a simpler way than just a graph.</p>
        </div>
        <div class="img3">
            <img src="../../IMGS/MDEF/Design_Studio/Second_Intervention/ECG.gif" height="350px">
        </div>
        <div class="texto5">
            <h2 class="subtitulo">Future for this intervention</h2>
            <p class="texto">As we didnâ€™t have much time to do the intervention, we had to cut it short, but what we have achieved opens up an incredible amount of possibilities for the future. By implementing the use of a smart citizen kit, we tried to see how the signal changes depending on the plant conditions, reducing the oxygen, sound lightâ€¦ By monitoring this while taking the electric signal, we can get huge datasets where we can study these changes and how to use them in our favor for sensor stuff. This is just the beginning of the project, and Iâ€™m happy to say that its future is bright</p>
        </div>
        <div class="img4">
            <img src="../../IMGS/MDEF/Design_Studio/Second_Intervention/GIF_Touch_Designer.gif" height="390px">
        </div>
        <div class="texto6">
            <h2 class="subtitulo">Community engagement</h2>
            <p class="texto">As we donâ€™t want our project to end here, we thought of engaging with communities. While we worked on the project, we found that thereâ€™s not a lot of technical info on the internet about this kind of project, so we decided to start creating a repo with our knowledge and setup for the project to be open source. This way, both people starting research in this area and people who already know about it can help each other develop this kind of sensoring project. The building of it is still in progress, so for now you can check the following slides, where weâ€™ve added a summary of our work.</p>
        </div>
        <div class="img5">
            <img src="../../IMGS/MDEF/Design_Studio/Second_Intervention/Test.png" height="350px">
        </div>
        <div class="texto7">
            <h2 class="subtitulo"></h2>
            <p class="texto"></p>
        </div>
        <div class="img6">
            
        </div>
        <div class="texto8">
            <h2 class="subtitulo"></h2>
            <p class="texto"></p>
            <p class="texto"></p>
        </div>
        <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vQqUmqyxZVejCguSnAaIkrQ_OjpYvseBwAvbUnGXDmm5FHIAGb0D1pIFpHVajNieyDW0Z-2p-adCtD1/embed?start=false&loop=false&delayms=3000" frameborder="0" width="1280" height="720" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
        <iframe width="1280" height="720" src="https://www.youtube.com/embed/3a1IpfX1REI?si=1JSc3-m96qiMblEd" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        <iframe width="1280" height="720" src="https://www.youtube.com/embed/v7DfLnNG7B8?si=Bmxg-WuHm360Ni6l" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>
    <div class="boton2">
        <a href="./9-Design_With_Others.html"><p class="boton2">ðŸ‘‰ Next Up: Design With Others</p></a>
    </div>
</body>
</html>